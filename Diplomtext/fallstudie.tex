Zur Überprüfung der praktischen Einsetzbarkeit der entwickelten Lösung wurde eine Fallstudie durchgeführt. Die Web Service-basierte Anwendung und die zugehörigen Tests, die dabei verwendet wurden, sind aus einem studentischen Projekt entstanden: "`Entwicklung einer Web Service-basierten Anwendung"' an der Universität Hannover am Fachgebiet Software Engineering (WS 2006/07). 
Innerhalb eines Semesters haben 8 Studenten die Anwendung entworfen, implementiert und getestet. Aufgrund der eingesetzten Technologien und Werkzeuge, wie BPEL (Kompositionsprache), BPELUnit-Framework (Testwerkzeug) und \textit{ActiveBPEL Engine}, hat sich das Projekt als Fallstudie für diese Arbeit angeboten. Zu erwähnen ist noch, dass die BPEL-Sprache noch in der Version 1.1 verwendet wurde.

Entwickelt wurde ein System für das Fachgebiet Software Engineering, das den Anmeldeprozess für studentische Abschlussarbeiten unterstützt. Das System stellt dabei sicher, dass alle wesentlichen Bestandteile der Betreuung, wie z.B. Veröffentlichung und Anmeldung der Abschlussarbeit, Planung von Zwischen- und Endvorträgen, Bewertung usw., eingehalten werden.
Für die Fallstudie sind vor allem die entstandenen BPEL-Prozesse und die Tests interessant. 

Zur besseren Einschätzung der Größe der entstandenen Anwendung und Einordnung dieser Fallstudie werden einige statistische Daten des BPEL-Prozesses und (BPELUnit-) Tests vorgestellt.  

Der Gesamtprozess besteht aus 12 Teilprozessen. Insgesamt wurden 13 BPEL-Dateien erstellt: 12 für Teilprozesse und eine für den Hauptprozess, der alle Teilprozesse (als Web Services) zu einer Anwendung verknüpft. Die Abbildung \ref{fig:beispielprozess} stellt den Zusammenhang grafisch dar.
Die folgenden Statistiken beziehen sich auf alle 13 BPEL-Dateien und zeigen welche Aktivitäten bei der Prozessmodellierung verwendet wurden.

\begin{figure}[htbp]
	\centering
		\includegraphics[width=\textwidth]{bilder/Fallstudie.png}
		\caption{BPEL-Prozess. }
	\label{fig:beispielprozess}
\end{figure}

Es wurden insgesamt 508 strukturierten Aktivitäten und Scopes verwendet:
\begin{table}[h!]
\begin{tabular}{p{2cm}p{0.5cm}p{2cm}}
\textbf{Aktivität}&\ &\textbf{Anzahl}\\[0.1cm]
\hline \\
flow&\ &237\\
pick&\ &1\\
switch&\ &71\\
while&\ &19\\
secuence&\ &0\\
scope&\ &180\\
\end{tabular}
\end{table}

\newpage
750 Basisaktivitäten:
\begin{table}[h!]
\begin{tabular}{p{3cm}p{3cm}p{3cm}p{1cm}}
\textbf{Aktivität}&\textbf{Anzahl}&\textbf{Aktivität}&\textbf{Anzahl}\\[0.1cm]
\hline \\
assign&387&compensate&0\\
empty&109&invoke&56\\
receive&21&reply&55\\
terminate&14&throw&98\\
wait&10&&\\
\end{tabular}
\end{table}

Auffällig ist, dass keine \textit{sequence}-Aktivitäten verwendet wurden;  sämtliche squentiellen Abläufe wurden mit Hilfe von Synchronistaionslinks in \textit{flow}-Aktivitäten modelliert. Es wurden insgesamt 596 Synchronisationslinks verwendet.

Zum Testen des Prozesses wurde BPELUnit-Framework eingesetzt.
Es wurden zwei Testsuites erstellt:
\begin{itemize}
	\item \textbf{Suite1} besteht aus 30 Testfällen und testet den gesamten Prozesses. In diesem Fall werden ausschließlich die Kommuniaktionspartner (Web Services) der Teilprozesse durch Mocks ersetzt. Die zugehörige Aufrufe sind in der Abbildung \ref{fig:beispielprozess} durch kurze Pfeile angedeutet. Das heißt, es wird ein Prozess getestet, der nicht in einer einzelnen BPEL-Datei beschrieben ist, sondern sich aus mehreren Teilprozessen zusammen setzt. Es werden also nicht die kleinsten Einheiten des Prozesses isoliert.
	\item \textbf{Suite2} besteht aus 12 Testfällen und testet die einzelnen Teilprozesse. Zusätzlich zu den Partnern, die bei \textit{suite1} durch Mocks ersetzt wurden, wird auch der Hauptprozess, der in diesem Fall Client ist, durch ein Client-Mock ersetzt.  
\end{itemize}

Die Teilprozesse werden sowohl in \textit{suite1} als auch in \textit{suite2} getestet. Um die gesamte Testabdeckung zu ermitteln, die durch beide Suites zusammen erreicht wird, müssen zum einen beide Testsuites ausgeführt und zum anderen dieselben Marken verwendet werden, um die abgedeckten Prozesselemente in beiden Testläufen identifizieren zu können. Das BPELUnit-Framework ist allerdings so konzipiert, dass nur eine suite pro Testlauf ausgeführt werden kann und die einzelnen Testläufe voneinander unabhängig sind. 
Die Messung der Testabdeckung erfolgt ebenfalls suite-bezogen. Das heißt, dass die Berechnung der Testabdeckung über mehrere Suites nicht möglich ist.
Für die Ermittlung der Testabdeckung mit dem BPELUnit-Framework ist es notwendig, dass alle Testfälle, die ein Prozess betreffen, in einer Testsuite zusammengeführt werden. 

Die Organisation der Testfälle im betrachteten Projekt erfüllt diese Anforderungen nicht. Aufgrund der unterschiedlichen Schnittstellen, die in den beiden Testsuites für die Clients vorgesehen sind, ist auch das Zusammenführen der beiden Suites  nicht möglich. Deswegen kann die Gesamtabdeckung, die beim Testen erreicht wird, nicht ermittelt werden. 
 
 Die praktische Einsetzbarkeit des Verfahrens für die Ermittlung der Testabdeckung und die Implementierung können trotzdem an diesem Projekt überprüft werden. Die Ermittlung der Testabdeckung für einzelnen Suites schafft in diesem Fall zwar keine Grundlage für die Bewertung der Tests zeigt aber die Funktionstüchtigkeit des entwickelten Werkzeugs an einem realen Projekt.

\textbf{Instrumentierung}. Bei der Instrumentierung werden die BPEL-Dateien (alle 13) für alle in dem Abschnitt \ref{sec:metrikdefinition} definierten Metriken instrumentiert. Einige statistischen Daten der Instrumentierungsphase folgen:
\begin{itemize}
	\item 2856 Marken,
	\item 1500 invoke- und assign-Aktivitäten,
	\item 1094 sequence-Aktivitäten,
	\item 4 flow-Aktivitäten.
\end{itemize}

Es werden insgesamt 2856 Marken im Prozess platziert. Die Übertragung der Marken wird durch 1502 \textit{invoke-}Aktivitäten realisiert. Durch das Zusammenfassen der Marken, die hintereinander im Kontrollfluss liegen, können 1356 \textit{invoke}-Aktivitäten gespart werden und damit die \textit{overhead}-Zeit, die durch Ausführung der Aktivitäten für die Übertragung der Marken zustande kommt, verringert werden.  Der getestete BPEL-Prozess enthält vier Links, die für die Linkabdeckung relevant sind.  Zur Erfassung des Linkstatus wurde für jeden Link, wie im Abschnitt \ref{sec:Linkabdeckung} beschrieben, eine \textit{flow}-Aktivität eingefügt.  Die vielen zusätzlichen \textit{sequence}-Aktivitäten werden vor allem durch Synchronisationslinks verursacht (siehe Abschnitt \ref{sec:aktivitaetsabdeckung} und \ref{sec:zweigabdeckung}), die im Originalprozess auch für die Modellierung der sequenziellen Abläufen eingesetzt werden.

\textbf{Ergebnisse}.
Die Ergebnisse sind in der folgenden Tabelle dargestellt.

\textbf{Testsuite1:}
\begin{table}[h!]
\begin{tabular}{p{7cm}p{2cm}p{2cm}p{2cm}}
\textbf{Aktivität}&\textbf{Anzahl}&\textbf{Aktivität}&\textbf{Anzahl}\\[0.1cm]
\hline \\
Activitätsabdeckung&750&468&62\%\\
\ \ \ assign&387&277&71\%\\
\ \ \ compensate&0&0&-\\
\ \ \ empty&109&91&83\%\\
\ \ \ invoke&56&56&100\%\\
\ \ \ receive&21&21&100\%\\
\ \ \ reply&55&23&41\%\\
\ \ \ terminate&14&0&0\%\\
\ \ \ throw&98&0&0\%\\
\ \ \ wait&10&0&0\%\\
Zweigabdeckung&1020&704&69\%\\
Linkabdeckung&8&6&75\%\\
\ \ \ negativ&4&3&75\%\\
\ \ \ positiv&4&3&75\%\\
Fault Handler-Abdeckung&64&0&0\%\\
Compensation Handler-Abdeckung&0&0&-\%\\
\end{tabular}
\end{table}
\FloatBarrier
\textbf{Testsuite2:}
\begin{table}[h!]
\begin{tabular}{p{7cm}p{2cm}p{2cm}p{2cm}}
\textbf{Aktivität}&\textbf{Anzahl}&\textbf{Aktivität}&\textbf{Anzahl}\\[0.1cm]
\hline \\
Activitätsabdeckung&750&378&50\%\\
\ \ \ assign&387&225&58\%\\
\ \ \ compensate&0&0&-\\
\ \ \ empty&109&85&77\%\\
\ \ \ invoke&56&44&78\%\\
\ \ \ receive&21&12&57\%\\
\ \ \ reply&55&12&21\%\\
\ \ \ terminate&14&0&0\%\\
\ \ \ throw&98&0&0\%\\
\ \ \ wait&10&0&0\%\\
Zweigabdeckung&1020&570&55\%\\
Linkabdeckung&8&2&25\%\\
\ \ \ negativ&4&1&25\%\\
\ \ \ positiv&4&1&25\%\\
Fault Handler-Abdeckung&64&0&0\%\\
Compensation Handler-Abdeckung&0&0&-\%\\
\end{tabular}
\end{table}


\FloatBarrier
Wie bereits erläutert, kann die Gesamtabdeckung aufgrund der Überschneidungen der Testsuites nicht ermittelt werden. Es fehlt damit die Grundlage für die Bewertung der Tests.

\textbf{Zeitmessungen}.
Die Testlaufzeiten werden aufgrund der zusätzlichen Instrumentierungsphase und neuen Aktivitäten im Prozess größer.
Die gemessenen Zeiten mit und ohne der Ermittlung der Testabdeckung sind in der Tabelle \ref{tab:testlaufzeiten} für die beiden Testsuites angegeben (in Sekunden).
Das System auf dem die Testlaufzeiten gemessen wurden hat folgende Charakteristiken:
\begin{itemize}
	\item CPU: AMD Athlon XP 2,17 GHz
	\item Speicher: 2GB
	\item Betriebssystem: Windows XP
\end{itemize}
Die verwendete Software ist im Anhang angegeben \ref{}.

 Nach jedem Testfall wird der Testlauf angehalten, um auf die Coverage-Nachrichten zu warten, die noch übertragen werden (siehe Abschnitt \ref{sec:coverageLoggingService}). Die Wartezeit kann durch den Tester bestimmt werden. Der optimale für diese Fallstudie Wert wurde experimentell ermittelt und beträgt 0,5 Sekunden.  Die gesamte Wartezeit für jede Testsuite ergibt sich aus der Anzahl der Testfälle und der Wartezeit pro Testfall und ist in der letzten Spalte angegeben. Die Instrumentierungsphase ist für die beiden Testsuites gleich und beträgt 2,2 Sekunden.
 \begin{table}[h!]
\begin{tabular}{p{7cm}p{2cm}p{3cm}}
&\textbf{Laufzeit}&\textbf{Wartezeit}\\[0.1cm]
Testsuite1&\\
\ \ \ \ \ \ \ \ \ ohne Messung der Testabdeckung&$24,3\ s$\\
\ \ \ \ \ \ \ \ \ mit Messung der Testabdeckung&$68,7\ s$&$0,5*30=15\ s$\\
\\
Testsuite2&\\
\ \ \ \ \ \ \ \ \ ohne Messung der Testabdeckung&$14,6\ s$\\
\ \ \ \ \ \ \ \ \ mit Messung der Testabdeckung&$32,8\ s$&$0,5*12=6\ s$\\
\end{tabular}
\caption{Fallstudie - Testlaufzeiten mit und ohne der Ermittlung der Testabdeckung}
\label{tab:testlaufzeiten}
\end{table}

In den Laufzeiten mit der Ermittlung der Testabdeckung ist die Instrumentierungszeit und Wartezeit enthalten.
Die Ausführungszeit hat sich bei der ersten Suite um Faktor 2,8 (ohne Instrumentierungsphase 2,7) und bei der zweiten um Faktor 2,2 (2,1) verlängert. Der Faktor  hängt sehr stark von dem getesteten Prozess und der Testlogik ab. Aus dem Grund lässt sich kein Faktor angeben, der allgemein gültig ist. 